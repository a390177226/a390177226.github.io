<!doctype html><html><head><title>python爬虫[2]--requests模块</title><meta charset=utf-8><meta name=X-UA-Compatible content="IE=edge"><meta name=google-site-verification content><meta content="width=device-width,initial-scale=1,maximum-scale=1,user-scalable=0" name=viewport><meta content="telephone=no" name=format-detection><meta name=description content><meta name=renderer content="webkit"><meta name=theme-color content="#ffffff"><script src=/vendor/js/jquery.min.js></script><script src=/vendor/js/popper.min.js></script><script src=/vendor/js/bootstrap.min.js></script><script src=/vendor/js/smooth-scroll.polyfills.min.js></script><link type=text/css rel=stylesheet href=/vendor/css/bootstrap.min.css><script src=/vendor/js/vue.min.js></script><link rel=stylesheet href=https://a390177226.github.io/scss/journal.min.579b9706a9598d23683f569ff063cd9cae54a7a2832e27345bc621e5d9b61d58.css integrity="sha256-V5uXBqlZjSNoP1af8GPNnK5Up6KDLic0W8Yh5dm2HVg=" media=screen><link rel=stylesheet href=https://a390177226.github.io/scss/dark-mode.min.c8808fcf21682127815c96de88e1b749dcb247b5937d839340d8146cf0945a25.css integrity="sha256-yICPzyFoISeBXJbeiOG3SdyyR7WTfYOTQNgUbPCUWiU=" media=screen><script src=https://a390177226.github.io//js/loadCSS.js></script><script>loadCSS("https://fonts.googleapis.com/css?family=Lora|Montserrat|Fira+Mono|Noto+Serif+SC|Material+Icons")</script><script src=https://a390177226.github.io//js/toc-collapse.js></script></head><body><div id=app><div ref=sideContainer class=side-container><a class="a-block nav-head false" href=https://a390177226.github.io/><div class=nav-title>ZZB's blog</div><div class=nav-subtitle>Record my study.</div></a><div class=nav-link-list><a class="a-block nav-link-item false" href=/categories>Categories</a>
<a class="a-block nav-link-item false" href=/tags>Tags</a>
<a class="a-block nav-link-item false" href=/post>文章</a>
<a class="a-block nav-link-item false" href=/%E5%89%8D%E7%AB%AF>前端</a>
<a class="a-block nav-link-item false" href=/research>Research</a>
<a class="a-block nav-link-item active" href=/python>Python</a></div><div class=nav-footer>Hugo Theme <a href=https://github.com/amazingrise/hugo-theme-diary>Diary</a> by <a href=https://amazingrise.net>Rise</a><br>Ported from <a href=https://mak1t0.cc/ target=_blank rel="noreferrer noopener">Makito</a>'s <a href=https://github.com/SumiMakito/hexo-theme-journal/ target=_blank rel="noreferrer noopener">Journal.</a><br><br>&copy;
zzb2021.</div></div><div ref=extraContainer class=extra-container><div class="toc animated-visibility" :class="{ invisible: scrollY <= 140 }"><div class=toc-content><center>- TOC -</center><ul><li><a href=#%e7%bd%91%e7%bb%9c%e8%af%b7%e6%b1%82%e6%a8%a1%e5%9d%97 onclick="onNavClick(`#网络请求模块-nav`)" id=网络请求模块-nav>网络请求模块</a></li><li><a href=#requests%e6%a8%a1%e5%9d%97 onclick="onNavClick(`#requests模块-nav`)" id=requests模块-nav>requests模块</a></li><li><a href=#topics onclick="onNavClick(`#topics-nav`)" id=topics-nav>topics</a></li><li><a href=#%e7%ac%ac%e4%b8%80%e4%b8%aa%e4%be%8b%e5%ad%90 onclick="onNavClick(`#第一个例子-nav`)" id=第一个例子-nav>第一个例子</a></li><li><a href=#%e7%ae%80%e6%98%93%e7%bd%91%e9%a1%b5%e9%87%87%e9%9b%86%e5%99%a8 onclick="onNavClick(`#简易网页采集器-nav`)" id=简易网页采集器-nav>简易网页采集器</a></li><li><a href=#%e7%88%ac%e5%8f%96%e5%8a%a8%e6%80%81%e5%8a%a0%e8%bd%bd%e6%95%b0%e6%8d%ae onclick="onNavClick(`#爬取动态加载数据-nav`)" id=爬取动态加载数据-nav>爬取动态加载数据</a></li><li><a href=#%e7%88%ac%e5%8f%96%e5%a4%9a%e9%a1%b5%e6%95%b0%e6%8d%ae onclick="onNavClick(`#爬取多页数据-nav`)" id=爬取多页数据-nav>爬取多页数据</a></li><li><a href=#%e4%bd%9c%e4%b8%9a onclick="onNavClick(`#作业-nav`)" id=作业-nav>作业</a></li></ul></div></div><div class=pagination><a id=globalBackToTop class="pagination-action animated-visibility" href=#top :class="{ invisible: scrollY == 0 }"><i class="material-icons pagination-action-icon">keyboard_arrow_up</i></a>
<a class=pagination-action v-on:click=toggleDarkMode><i class="material-icons pagination-action-icon" v-if=isDarkMode>brightness_4</i>
<i class="material-icons pagination-action-icon" v-else=isDarkMode>brightness_7</i></a></div></div><div class=single-column-drawer-container ref=drawer v-bind:class="{ 'single-column-drawer-container-active': isDrawerOpen }"><div class=drawer-content><div class=drawer-menu><a class="a-block drawer-menu-item false" href=/categories>Categories</a>
<a class="a-block drawer-menu-item false" href=/tags>Tags</a>
<a class="a-block drawer-menu-item false" href=/post>文章</a>
<a class="a-block drawer-menu-item false" href=/%E5%89%8D%E7%AB%AF>前端</a>
<a class="a-block drawer-menu-item false" href=/research>Research</a>
<a class="a-block drawer-menu-item active" href=/python>Python</a><div class=toc><div class=toc-content><center>- TOC -</center><ul><li><a href=#%e7%bd%91%e7%bb%9c%e8%af%b7%e6%b1%82%e6%a8%a1%e5%9d%97 onclick="onNavClick(`#网络请求模块-nav`)" id=网络请求模块-nav>网络请求模块</a></li><li><a href=#requests%e6%a8%a1%e5%9d%97 onclick="onNavClick(`#requests模块-nav`)" id=requests模块-nav>requests模块</a></li><li><a href=#topics onclick="onNavClick(`#topics-nav`)" id=topics-nav>topics</a></li><li><a href=#%e7%ac%ac%e4%b8%80%e4%b8%aa%e4%be%8b%e5%ad%90 onclick="onNavClick(`#第一个例子-nav`)" id=第一个例子-nav>第一个例子</a></li><li><a href=#%e7%ae%80%e6%98%93%e7%bd%91%e9%a1%b5%e9%87%87%e9%9b%86%e5%99%a8 onclick="onNavClick(`#简易网页采集器-nav`)" id=简易网页采集器-nav>简易网页采集器</a></li><li><a href=#%e7%88%ac%e5%8f%96%e5%8a%a8%e6%80%81%e5%8a%a0%e8%bd%bd%e6%95%b0%e6%8d%ae onclick="onNavClick(`#爬取动态加载数据-nav`)" id=爬取动态加载数据-nav>爬取动态加载数据</a></li><li><a href=#%e7%88%ac%e5%8f%96%e5%a4%9a%e9%a1%b5%e6%95%b0%e6%8d%ae onclick="onNavClick(`#爬取多页数据-nav`)" id=爬取多页数据-nav>爬取多页数据</a></li><li><a href=#%e4%bd%9c%e4%b8%9a onclick="onNavClick(`#作业-nav`)" id=作业-nav>作业</a></li></ul></div></div></div></div></div><transition name=fade><div v-bind:class="{ 'single-column-drawer-mask': mounted }" v-if=isDrawerOpen v-on:click=toggleDrawer></div></transition><nav ref=navBar class="navbar sticky-top navbar-light single-column-nav-container"><div ref=navBackground class=nav-background></div><div class="container container-narrow nav-content"><button id=nav_dropdown_btn class=nav-dropdown-toggle type=button v-on:click=toggleDrawer>
<i class=material-icons>menu</i></button>
<a ref=navTitle class=navbar-brand href=https://a390177226.github.io/>ZZB's blog</a>
<button type=button class=nav-darkmode-toggle v-on:click=toggleDarkMode>
<i class=material-icons v-if=isDarkMode>brightness_4</i>
<i class=material-icons v-else=isDarkMode>brightness_7</i></button></div></nav><div class=single-column-header-container ref=pageHead v-bind:style="{ transform: 'translateZ(0px) translateY('+.3*scrollY+'px)', opacity: 1-navOpacity }"><a href=https://a390177226.github.io/><div class=single-column-header-title>ZZB's blog</div><div class=single-column-header-subtitle>Record my study.</div></a></div><div id=content><div ref=streamContainer class=stream-container><div class="post-list-container post-list-container-shadow"><div class=post><div class=post-head-wrapper-text-only><div class=post-title>python爬虫[2]--requests模块<div class=post-meta><time itemprop=datePublished>2021-06-10 15:07</time>
<i class=material-icons>folder</i>
<a href=/categories/python>python</a>
&nbsp;
<i class=material-icons>label</i>
<a href=/tags/%E7%88%AC%E8%99%AB>爬虫</a>
&nbsp;</div></div></div><div class=post-body-wrapper><div class=post-body v-pre><h1 id=网络请求模块>网络请求模块</h1><ul><li>urllib模块：古老繁琐</li><li>requests模块：简洁高效</li></ul><h1 id=requests模块>requests模块</h1><p>python中原生的一款基于网络请求的模块，功能非常强大，简单便捷，效率极高。</p><p>作用：模拟浏览器发送请求。</p><p>安装：<code>pip install requests</code></p><h1 id=topics>topics</h1><ul><li>数据解析</li><li>动态数据的爬取</li><li>selenium</li><li>移动端数据的爬取</li><li>异步的爬虫</li><li>10种反爬机制</li></ul><h1 id=第一个例子>第一个例子</h1><p>爬取搜狗首页的页面数据</p><div class=highlight><pre style=background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#8b008b;font-weight:700>import</span> <span style=color:#008b45;text-decoration:underline>requests</span>
<span style=color:#228b22># step1: 指定url</span>
url = <span style=color:#cd5555>&#39;https://www.sogou.com/&#39;</span>

<span style=color:#228b22># step2：发起请求</span>
<span style=color:#228b22># get方法会返回一个响应对象</span>
response = requests.get(url=url)

<span style=color:#228b22># step3: 获取响应数据</span>
<span style=color:#228b22># .text返回的是字符串形式的响应数据</span>
page_text = response.text

<span style=color:#228b22># step4: 持久化存储</span>
<span style=color:#8b008b;font-weight:700>with</span> <span style=color:#658b00>open</span>(<span style=color:#cd5555>&#39;./sogou.html&#39;</span>,<span style=color:#cd5555>&#39;w&#39;</span>,encoding=<span style=color:#cd5555>&#39;utf-8&#39;</span>) <span style=color:#8b008b;font-weight:700>as</span> fp:
    fp.write(page_text)
</code></pre></div><h1 id=简易网页采集器>简易网页采集器</h1><p>基于搜狗针对指定不同的关键字将其对应的页面数据进行爬取</p><div class=highlight><pre style=background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python>keyWord = <span style=color:#658b00>input</span>(<span style=color:#cd5555>&#39;enter a key word:&#39;</span>)

<span style=color:#228b22># 携带了请求参数的url，如果想要爬取不同关键字对应的页面，我们需要将url携带的参数进行动态化</span>
<span style=color:#228b22># 实现参数动态化：</span>
params = {
    <span style=color:#cd5555>&#39;query&#39;</span>:keyWord
}

url = <span style=color:#cd5555>&#39;https://www.sogou.com/web&#39;</span>
<span style=color:#228b22># params参数（字典）：保存请求时url携带的参数</span>
response = requests.get(url=url, params=params)
<span style=color:#228b22># 修改响应数据的编码格式</span>
response.encoding = <span style=color:#cd5555>&#39;utf-8&#39;</span>

page_text = response.text
fileName = keyWord + <span style=color:#cd5555>&#39;.html&#39;</span>
<span style=color:#8b008b;font-weight:700>with</span> <span style=color:#658b00>open</span>(fileName, <span style=color:#cd5555>&#39;w&#39;</span>, encoding=<span style=color:#cd5555>&#39;utf-8&#39;</span>) <span style=color:#8b008b;font-weight:700>as</span> fp:
    fp.write(page_text)

<span style=color:#8b008b;font-weight:700>print</span>(fileName, <span style=color:#cd5555>&#39;爬取完毕！！！&#39;</span>)
</code></pre></div><p>页面显示【异常访问请求】导致请求数据的缺失</p><ul><li><p>异常访问请求：不是通过浏览器发起的请求</p><ul><li>网站后台已经检测出该次请求不是通过浏览器发起的，而是通过爬虫程序发起的请求</li></ul></li><li><p>网站的后台是如何知道请求是不是通过浏览器发起的呢？</p><ul><li>是通过判定请求的请求头部中的user-agent判定的</li><li>什么是user-agent：请求载体的身份标识</li><li>什么是请求载体<ul><li>浏览器：身份标识是统一固定的，可以通过抓包工具中获取</li><li>爬虫程序：身份标识是各自不同的</li></ul></li></ul></li></ul><blockquote><p>第一个反爬机制：</p><ul><li>robots协议</li></ul><p>第二个反爬机制：</p><ul><li>UA检测：网站后台会检测请求对应的user-agent，判定当前请求是否为异常请求</li></ul><p>反反爬机制：</p><ul><li>UA伪装</li><li>伪装流程：<ul><li>从抓包工具中捕获到某一个基于浏览器请求的user-agent的值，将其伪装到一个字典中</li><li>将该字典作用到请求方法（get，post）的headers参数中即可</li></ul></li></ul></blockquote><div class=highlight><pre style=background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python>keyWord = <span style=color:#658b00>input</span>(<span style=color:#cd5555>&#39;enter a key word:&#39;</span>)
<span style=color:#228b22># 用来实现UA伪装</span>
headers = {
    <span style=color:#cd5555>&#39;user-agent&#39;</span>:<span style=color:#cd5555>&#39;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.101 Safari/537.36 Edg/91.0.864.48&#39;</span>
}
<span style=color:#228b22># 实现参数动态化：</span>
params = {
    <span style=color:#cd5555>&#39;query&#39;</span>:keyWord
}

url = <span style=color:#cd5555>&#39;https://www.sogou.com/web&#39;</span>
<span style=color:#228b22># params参数（字典）：保存请求时url携带的参数</span>
response = requests.get(url=url, params=params, headers = headers)
<span style=color:#228b22># 修改响应数据的编码格式</span>
response.encoding = <span style=color:#cd5555>&#39;utf-8&#39;</span>

page_text = response.text
fileName = keyWord + <span style=color:#cd5555>&#39;.html&#39;</span>
<span style=color:#8b008b;font-weight:700>with</span> <span style=color:#658b00>open</span>(fileName, <span style=color:#cd5555>&#39;w&#39;</span>, encoding=<span style=color:#cd5555>&#39;utf-8&#39;</span>) <span style=color:#8b008b;font-weight:700>as</span> fp:
    fp.write(page_text)

<span style=color:#8b008b;font-weight:700>print</span>(fileName, <span style=color:#cd5555>&#39;爬取完毕！！！&#39;</span>)
</code></pre></div><h1 id=爬取动态加载数据>爬取动态加载数据</h1><p>爬取豆瓣电影中的电影详情数据</p><div class=highlight><pre style=background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#228b22># 一个爬取失败的例子</span>
url = <span style=color:#cd5555>&#39;https://movie.douban.com/typerank?type_name=</span><span style=color:#cd5555>%E</span><span style=color:#cd5555>5%8A%A8</span><span style=color:#cd5555>%E</span><span style=color:#cd5555>4%BD%9C&amp;type=5&amp;interval_id=100:90&amp;action=&#39;</span>
response = requests.get(url=url, headers = headers)
page_text = response.text
fileName = <span style=color:#cd5555>&#39;./douban.html&#39;</span>
<span style=color:#8b008b;font-weight:700>with</span> <span style=color:#658b00>open</span>(fileName, <span style=color:#cd5555>&#39;w&#39;</span>, encoding=<span style=color:#cd5555>&#39;utf-8&#39;</span>) <span style=color:#8b008b;font-weight:700>as</span> fp:
    fp.write(page_text)
</code></pre></div><p>动态加载数据的捕获</p><ul><li>什么是动态加载的数据？<ul><li>我们通过requests模块进行数据爬取无法每次都实现可见即可得</li><li>有些数据是通过非浏览器地址栏中的url请求到的数据，而是其他请求请求到的数据，那么这些数据就是动态加载数据</li></ul></li><li>如何检测网页中是否存在动态加载数据？<ul><li>基于抓包工具进行局部搜索<ul><li>在当前网页中打开抓包工具，找到到地址栏的url对应的数据包</li><li>在该数据包的response选项卡搜索想要爬取的数据</li><li>如果搜索到了结果，则表示数据不是动态加载的，否则表示数据是动态加载的</li></ul></li></ul></li><li>如何捕获到动态加载的数据？<ul><li>基于抓包工具进行全局搜索</li><li>定位到动态加载数据对应的数据包，可以从中提取出<ul><li>请求的url</li><li>请求方式</li><li>请求携带的参数</li><li>看到响应数据</li></ul></li></ul></li></ul><div class=highlight><pre style=background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python>url = <span style=color:#cd5555>&#39;https://movie.douban.com/j/chart/top_list&#39;</span>
params = {
    <span style=color:#cd5555>&#39;type&#39;</span>: <span style=color:#cd5555>&#39;5&#39;</span>,
	<span style=color:#cd5555>&#39;interval_id&#39;</span>: <span style=color:#cd5555>&#39;100:90&#39;</span>,
	<span style=color:#cd5555>&#39;action&#39;</span>: <span style=color:#cd5555>&#39;&#39;</span>,
	<span style=color:#cd5555>&#39;start&#39;</span>: <span style=color:#cd5555>&#39;0&#39;</span>,
	<span style=color:#cd5555>&#39;limit&#39;</span>: <span style=color:#cd5555>&#39;20&#39;</span>
}

response = requests.get(url=url, params=params, headers = headers)
<span style=color:#228b22># .json()将获取的字符串形式的json数据序列化成字典或者列表对象</span>
page_text = response.json()
<span style=color:#228b22># 解析出电影的名称+评分</span>
<span style=color:#8b008b;font-weight:700>for</span> movie <span style=color:#8b008b>in</span> page_text:
    name = movie[<span style=color:#cd5555>&#39;title&#39;</span>]
    score = movie[<span style=color:#cd5555>&#39;score&#39;</span>]
    <span style=color:#8b008b;font-weight:700>print</span>(name,score)
<span style=color:#228b22># 或者持久化存储   </span>
<span style=color:#8b008b;font-weight:700>with</span> <span style=color:#658b00>open</span>(<span style=color:#cd5555>&#34;./test&#34;</span>, <span style=color:#cd5555>&#34;w&#34;</span>, encoding=<span style=color:#cd5555>&#39;utf-8&#39;</span>) <span style=color:#8b008b;font-weight:700>as</span> fp:
    <span style=color:#8b008b;font-weight:700>for</span> movie <span style=color:#8b008b>in</span> page_text:
        name = movie[<span style=color:#cd5555>&#39;title&#39;</span>]
        score = movie[<span style=color:#cd5555>&#39;score&#39;</span>]
        eachRow = name+<span style=color:#cd5555>&#39;</span><span style=color:#cd5555>\t</span><span style=color:#cd5555>&#39;</span>+score+<span style=color:#cd5555>&#39;</span><span style=color:#cd5555>\n</span><span style=color:#cd5555>&#39;</span>
        fp.write(eachRow)
</code></pre></div><blockquote><p>思考：基于抓包工具进行全局搜索不一定可以每次都能定位到动态加载数据对应的数据包？</p><p>原因：动态加载的数据是经过加密的密文数据</p></blockquote><h1 id=爬取多页数据>爬取多页数据</h1><p>爬取肯德基的餐厅位置数据</p><ul><li>url：<a href=http://www.kfc.com.cn/kfccda/storelist/>http://www.kfc.com.cn/kfccda/storelist/</a></li></ul><p>分析</p><ul><li>在餐厅关键字的文本框中输入关键字按下搜索按钮，发起的是一个ajax请求<ul><li>当前页面刷新出来的位置信息一定是通过ajax请求请求到的数据</li><li>基于抓包工具定位到该ajax请求的数据包，从该数据包中捕获到：<ul><li>请求的url</li><li>请求方式</li><li>请求携带的参数</li><li>看到响应数据</li></ul></li></ul></li></ul><div class=highlight><pre style=background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#228b22># 爬取第1页的数据</span>
url = <span style=color:#cd5555>&#39;http://www.kfc.com.cn/kfccda/ashx/GetStoreList.ashx?op=keyword&#39;</span>
<span style=color:#228b22># data参数是post方法中处理参数动态化的参数</span>
data = {
    <span style=color:#cd5555>&#39;cname&#39;</span>: <span style=color:#cd5555>&#39;&#39;</span>,
    <span style=color:#cd5555>&#39;pid&#39;</span>: <span style=color:#cd5555>&#39;&#39;</span>,
    <span style=color:#cd5555>&#39;keyword&#39;</span>: <span style=color:#cd5555>&#39;北京&#39;</span>,
    <span style=color:#cd5555>&#39;pageIndex&#39;</span>: <span style=color:#cd5555>&#39;1&#39;</span>,
    <span style=color:#cd5555>&#39;pageSize&#39;</span>: <span style=color:#cd5555>&#39;10&#39;</span>
}

response = requests.post(url=url, data=data, headers = headers)
page_text = response.json()

<span style=color:#8b008b;font-weight:700>for</span> dic <span style=color:#8b008b>in</span> page_text[<span style=color:#cd5555>&#39;Table1&#39;</span>]:
    title = dic[<span style=color:#cd5555>&#39;storeName&#39;</span>]
    addr = dic[<span style=color:#cd5555>&#39;addressDetail&#39;</span>]
    <span style=color:#8b008b;font-weight:700>print</span>(title,addr)
</code></pre></div><div class=highlight><pre style=background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#228b22># 爬取多页</span>
url = <span style=color:#cd5555>&#39;http://www.kfc.com.cn/kfccda/ashx/GetStoreList.ashx?op=keyword&#39;</span>

data = {
    <span style=color:#cd5555>&#39;cname&#39;</span>: <span style=color:#cd5555>&#39;&#39;</span>,
    <span style=color:#cd5555>&#39;pid&#39;</span>: <span style=color:#cd5555>&#39;&#39;</span>,
    <span style=color:#cd5555>&#39;keyword&#39;</span>: <span style=color:#cd5555>&#39;北京&#39;</span>,
    <span style=color:#cd5555>&#39;pageIndex&#39;</span>: <span style=color:#cd5555>&#39;1&#39;</span>,
    <span style=color:#cd5555>&#39;pageSize&#39;</span>: <span style=color:#cd5555>&#39;10&#39;</span>
}

response = requests.post(url=url, data=data, headers = headers)
page_text = response.json()

<span style=color:#8b008b;font-weight:700>for</span> dic <span style=color:#8b008b>in</span> page_text[<span style=color:#cd5555>&#39;Table1&#39;</span>]:
    title = dic[<span style=color:#cd5555>&#39;storeName&#39;</span>]
    addr = dic[<span style=color:#cd5555>&#39;addressDetail&#39;</span>]
    <span style=color:#8b008b;font-weight:700>print</span>(title,addr)
</code></pre></div><h1 id=作业>作业</h1><p>爬取化药监总局中的企业详情数据</p><ul><li>url：<a href=http://scxk.nmpa.gov.cn:81/xk/>http://scxk.nmpa.gov.cn:81/xk/</a></li><li>需求：<ul><li>将首页中每一家企业的详情数据进行爬取</li><li>将前5页的数据爬取即可</li></ul></li><li>难点：<ul><li>用不到数据解析</li><li>所有的数据都是动态加载出来的</li></ul></li><li>提示：<ul><li>先爬取一家企业，然后再爬取多家</li></ul></li></ul><ol><li><div class=highlight><pre style=background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#228b22># 爬取第1、2页的公司ID</span>
url = <span style=color:#cd5555>&#39;http://scxk.nmpa.gov.cn:81/xk/itownet/portalAction.do?method=getXkzsList&#39;</span>
   
all_id_list = []
<span style=color:#8b008b;font-weight:700>for</span> page <span style=color:#8b008b>in</span> <span style=color:#658b00>range</span>(<span style=color:#b452cd>1</span>,<span style=color:#b452cd>3</span>):
    data = {
        <span style=color:#cd5555>&#39;on&#39;</span>: <span style=color:#cd5555>&#39;true&#39;</span>,
        <span style=color:#cd5555>&#39;page&#39;</span>: <span style=color:#658b00>str</span>(page),
        <span style=color:#cd5555>&#39;pageSize&#39;</span>: <span style=color:#cd5555>&#39;15&#39;</span>,
        <span style=color:#cd5555>&#39;productName&#39;</span>: <span style=color:#cd5555>&#39;&#39;</span>,
        <span style=color:#cd5555>&#39;conditionType&#39;</span>: <span style=color:#cd5555>&#39;1&#39;</span>,
        <span style=color:#cd5555>&#39;applyname&#39;</span>: <span style=color:#cd5555>&#39;&#39;</span>,
        <span style=color:#cd5555>&#39;applysn&#39;</span>: <span style=color:#cd5555>&#39;&#39;</span>
    }
   
    response = requests.post(url=url, data=data, headers = headers)
    json_text = response.json()
   
    <span style=color:#228b22># all_id_list用于二级页面数据获取</span>
    <span style=color:#8b008b;font-weight:700>for</span> <span style=color:#658b00>dict</span> <span style=color:#8b008b>in</span> json_text[<span style=color:#cd5555>&#39;list&#39;</span>]:
        ID  = <span style=color:#658b00>dict</span>[<span style=color:#cd5555>&#39;ID&#39;</span>]
        all_id_list.append(ID)
   
<span style=color:#228b22># 根据ID，爬取二级页面</span>
all_data_list = []
post_url = <span style=color:#cd5555>&#39;http://scxk.nmpa.gov.cn:81/xk/itownet/portalAction.do?method=getXkzsById&#39;</span>
   
<span style=color:#8b008b;font-weight:700>for</span> <span style=color:#658b00>id</span> <span style=color:#8b008b>in</span>  all_id_list:
    post_data = {
        <span style=color:#cd5555>&#39;id&#39;</span>:<span style=color:#658b00>id</span>
    }
    response = requests.post(url=post_url,data=post_data,headers=headers)
    json_text = response.json()
    <span style=color:#8b008b;font-weight:700>print</span>(json_text[<span style=color:#cd5555>&#39;businessPerson&#39;</span>])
    all_data_list.append(json_text)
   
<span style=color:#228b22># 持久化存储</span>
<span style=color:#8b008b;font-weight:700>import</span> <span style=color:#008b45;text-decoration:underline>json</span>
<span style=color:#8b008b;font-weight:700>with</span> <span style=color:#658b00>open</span>(<span style=color:#cd5555>&#39;./allData.json&#39;</span>,<span style=color:#cd5555>&#39;w&#39;</span>,encoding=<span style=color:#cd5555>&#39;utf-8&#39;</span>) <span style=color:#8b008b;font-weight:700>as</span> fp:
    json.dump(all_data_list,fp=fp,ensure_ascii=False)
       
<span style=color:#8b008b;font-weight:700>print</span>(<span style=color:#cd5555>&#39;Over!!!&#39;</span>)
</code></pre></div></li></ol><hr width=100% id=EOF><p style=color:#777>最后修改于 2021-06-10</p></div></div><nav class=post-pagination><a class=newer-posts href=https://a390177226.github.io/python/dataparse/>Next<br>python爬虫[3]--数据解析</a>
<a class=older-posts href=https://a390177226.github.io/python/webscraper_overview/>Previous<br>python爬虫[1]--概述</a></nav><div class=post-comment-wrapper></div></div></div></div></div><div id=single-column-footer>Hugo Theme <a href=https://github.com/amazingrise/hugo-theme-diary>Diary</a> by <a href=https://amazingrise.net>Rise</a><br>Ported from <a href=https://mak1t0.cc/ target=_blank rel="noreferrer noopener">Makito</a>'s <a href=https://github.com/SumiMakito/hexo-theme-journal/ target=_blank rel="noreferrer noopener">Journal.</a><br><br>&copy;
zzb2021.</div></div><script>let app;app=new Vue({el:'#app',data:{scrollY:0,navOpacity:0,isDrawerOpen:!1,mounted:!1,isDarkMode:!1},methods:{sgn(a,b){let c=1/(1-2*a);return b<=a?0:b>=1-a?1:c*(b-a)},handleScroll(){this.scrollY=window.scrollY,this.navOpacity=this.sgn(0,Math.min(1,Math.max(0,window.scrollY/(this.pageHeadHeight()-this.navBarHeight()*.8))));const{navBar:c,navBackground:a,navTitle:b,extraContainer:d,streamContainer:e}=this.$refs;this.navOpacity>=1?(a.style.opacity=1,b.style.opacity=1):(a.style.opacity=0,b.style.opacity=0)},handleResize(){const{navBar:c,navBackground:d,navTitle:e,extraContainer:a,streamContainer:b}=this.$refs;a.style.left=b.offsetWidth-a.offsetWidth+'px'},navBarHeight(){return this.$refs.navBar.offsetHeight},pageHeadHeight(){return this.$refs.pageHead.offsetHeight},toggleDrawer(){this.isDrawerOpen=!this.isDrawerOpen,document.getElementsByTagName('html')[0].style.overflow=this.isDrawerOpen?'hidden':'unset'},closeDrawer(){this.isDrawerOpen=!1,document.getElementsByTagName('html')[0].style.overflow=this.isDrawerOpen?'hidden':'unset'},toggleDarkMode(){this.isDarkMode=!this.isDarkMode,this.isDarkMode==!0?(document.cookie="night=1;path=/",document.body.classList.add("night")):(document.cookie="night=0;path=/",document.body.classList.remove("night"))}},created(){window.addEventListener('scroll',this.handleScroll),window.addEventListener('resize',this.handleResize),window._nonDesktop=function(){let a=!1;return function(b){(/(android|bb\d+|meego).+mobile|avantgo|bada\/|blackberry|blazer|compal|elaine|fennec|hiptop|iemobile|ip(hone|od)|iris|kindle|lge |maemo|midp|mmp|mobile.+firefox|netfront|opera m(ob|in)i|palm( os)?|phone|p(ixi|re)\/|plucker|pocket|psp|series(4|6)0|symbian|treo|up\.(browser|link)|vodafone|wap|windows ce|xda|xiino|android|ipad|playbook|silk/i.test(b)||/1207|6310|6590|3gso|4thp|50[1-6]i|770s|802s|a wa|abac|ac(er|oo|s\-)|ai(ko|rn)|al(av|ca|co)|amoi|an(ex|ny|yw)|aptu|ar(ch|go)|as(te|us)|attw|au(di|\-m|r |s )|avan|be(ck|ll|nq)|bi(lb|rd)|bl(ac|az)|br(e|v)w|bumb|bw\-(n|u)|c55\/|capi|ccwa|cdm\-|cell|chtm|cldc|cmd\-|co(mp|nd)|craw|da(it|ll|ng)|dbte|dc\-s|devi|dica|dmob|do(c|p)o|ds(12|\-d)|el(49|ai)|em(l2|ul)|er(ic|k0)|esl8|ez([4-7]0|os|wa|ze)|fetc|fly(\-|_)|g1 u|g560|gene|gf\-5|g\-mo|go(\.w|od)|gr(ad|un)|haie|hcit|hd\-(m|p|t)|hei\-|hi(pt|ta)|hp( i|ip)|hs\-c|ht(c(\-| |_|a|g|p|s|t)|tp)|hu(aw|tc)|i\-(20|go|ma)|i230|iac( |\-|\/)|ibro|idea|ig01|ikom|im1k|inno|ipaq|iris|ja(t|v)a|jbro|jemu|jigs|kddi|keji|kgt( |\/)|klon|kpt |kwc\-|kyo(c|k)|le(no|xi)|lg( g|\/(k|l|u)|50|54|\-[a-w])|libw|lynx|m1\-w|m3ga|m50\/|ma(te|ui|xo)|mc(01|21|ca)|m\-cr|me(rc|ri)|mi(o8|oa|ts)|mmef|mo(01|02|bi|de|do|t(\-| |o|v)|zz)|mt(50|p1|v )|mwbp|mywa|n10[0-2]|n20[2-3]|n30(0|2)|n50(0|2|5)|n7(0(0|1)|10)|ne((c|m)\-|on|tf|wf|wg|wt)|nok(6|i)|nzph|o2im|op(ti|wv)|oran|owg1|p800|pan(a|d|t)|pdxg|pg(13|\-([1-8]|c))|phil|pire|pl(ay|uc)|pn\-2|po(ck|rt|se)|prox|psio|pt\-g|qa\-a|qc(07|12|21|32|60|\-[2-7]|i\-)|qtek|r380|r600|raks|rim9|ro(ve|zo)|s55\/|sa(ge|ma|mm|ms|ny|va)|sc(01|h\-|oo|p\-)|sdk\/|se(c(\-|0|1)|47|mc|nd|ri)|sgh\-|shar|sie(\-|m)|sk\-0|sl(45|id)|sm(al|ar|b3|it|t5)|so(ft|ny)|sp(01|h\-|v\-|v )|sy(01|mb)|t2(18|50)|t6(00|10|18)|ta(gt|lk)|tcl\-|tdg\-|tel(i|m)|tim\-|t\-mo|to(pl|sh)|ts(70|m\-|m3|m5)|tx\-9|up(\.b|g1|si)|utst|v400|v750|veri|vi(rg|te)|vk(40|5[0-3]|\-v)|vm40|voda|vulc|vx(52|53|60|61|70|80|81|83|85|98)|w3c(\-| )|webc|whit|wi(g |nc|nw)|wmlb|wonu|x700|yas\-|your|zeto|zte\-/i.test(b.substr(0,4)))&&(a=!0)}(navigator.userAgent||navigator.vendor||window.opera),a};var a=document.cookie.replace(/(?:(?:^|.*;\s*)night\s*\=\s*([^;]*).*$)|^.*$/,"$1");a==""?window.matchMedia&&window.matchMedia('(prefers-color-scheme: dark)').matches:a=="1"&&this.toggleDarkMode()},mounted(){this.handleScroll(),this.handleResize(),this.mounted=!0},destroyed(){window.removeEventListener('scroll',this.handleScroll),window.removeEventListener('resize',this.handleResize)}})</script><script src=https://a390177226.github.io//js/journal.js></script></body></html>